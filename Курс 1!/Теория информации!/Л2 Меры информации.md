При рассмотрении мер информации берутся во внимание три аспекта:

| Аспект/Подход  | Суть/Назначение                                                                                                         | Пояснение                                                                                       |
| -------------- | ----------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| Структурный    | В этом подходе рассматривается строение массивов информации и их измерением простым подсчётов информационных элементов. | Применяется для оценки возможности применения информационных систем вне зависимости от условий. |
| Статистический | В этом подходе рассматривается вероятность появления и информативность того или иного сообщения.                        | Учитывает конкретные условия применения информационных систем.                                  |
| Семантический  | Рассматривается полезность и ценность информационного сообщения.                                                        | Даётся оценка содержания разнохарактерной информации.                                           |
##### Структурная мера информации

При использовании структурных мер учитывается только дискретное строение сообщения.
![[Drawing 2025-03-21 11.20.59.excalidraw]]
При структурном подходе применяются три меры: геометрическая, комбинаторная, аддитивная.

`Геометрическая мера` предполагает измерение параметров геометрической модели сообщения (длина, площадь, объём) в дискретных единицах.  В качестве примера может быть линия определённой длины, площадь квадрата, объём куба и т.д. При этом длина - одноразрядное слово, площадь - двухразрядное слово, объём - трёхразрядное слово. Сумма элементов.

`Информационная ёмкость модели` - максимально возможное количество информации в заданной структуре.

`Комбинаторная мера` - число комбинаций элементов.

`Аддитивная мера` (мера Хартли) - Вводятся 2 понятия: глубина числа q - количество символов или элементов, принятых для представления информации; n - длина числа - количество позиций, достаточных для представления чисел. При заданных глубине и длине числа, общее количество информации $N = q^n$. $I(g) = log2N = log2q^n$. При наличии нескольких источников информации общее количество информации будет следующим: $I(g1, g2, g3, g4) = I(g1) + I(g2) + I(g3) + I(g4)$. Единица информации - бит. Один бит соответствует одному элементарному событию, которое может произойти или не произойти. За единицу количества информации принимается такое количество информации, которое содержит сообщение, уменьшающее неопределённость в 2 раза.

`Статистическая мера информации` - при статистическом (вероятностном) подходе важно не само событие, а информация о нём.

##### Формула Шенона
$N$ - общее кол-во опытов
$K$ - количество типов опытов
$j$ - исход опыта
$nj$ - опыт с j исходом
$Ij$ - количество информации, вносимой опытом с j исходом
$Pj$ - вероятность опыта с j исходом

$I(j) = log8({1 \over Pj}) = -log2(Pj)$
$Icp = {n1*I1+n2*I2+...+nk*Ik \over N} = {n1*log2P1+n2*log2P2+...+nk*log2PK \over N} = -(P1log2p1+P2log2P2+...+Pklog2PK) = \sum_{j=1}^{k}Pjlog2Pj = H$
`Энтропия` - мера неопределённости информации.

Свойства энтропии:
- $H > 0$ (всегда не отрицательна)
- $H = 0$ когда об опыте всё известно заранее ($Pi$ = 1)
- $Hmax$ когда вероятности всех событий равны между собой $Iшен = Iхар$
- $H(A, B) = H(A) + H(B)$

`Семантическая мера` - важны содержательность события, целесообразность, логическое количество, целесообразность и существенность информации.

Содержательность выражается через функцию меры $m(i)$ - содержательности его отрицания. Оценка содержательности основана на математической логике и изменяется в пределах $0 <= m(i) <= 1$

`Логическое количество` сходно со статистическим и вычисляется по формуле:
$Iuf = log2({I \over m(i)}) = -log2m(¬i)$

Информация оценивается по оказываемому эффекту на результат.

`Целесообразность` - изменение вероятности достижения цели при получении дополнительной информации. Информация может быть пустой, добротной и дезинформацией. Мера целесообразности может быть аналитически выражена через выражение
$Iцел = log2p1 - log2p0 = log2({p1 \over p0})$
$p0$ - конечная вероятность достижения цели (до получения информации)
$p1$ - конечная вероятность достижения цели (после)