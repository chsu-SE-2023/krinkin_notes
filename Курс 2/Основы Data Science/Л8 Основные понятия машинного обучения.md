Искусственный интеллект способен решать разообразные, но узкоспециализированные прикладные задачи.

#### Регрессия

==Регрессия== - задача на на поиск формулы для предсказания какого-либо вещественного числа. Обычно задача уже решена для различных областей. Обычно эти задачи имеют в себе около 70 различных параметров.
Регрессия должна быть обновлена по мере появления новых данных, иначе прогноз исходя из регрессии окажется неактуальным.

#### Классификация

==Классификация== - это определение заранее известного и описанного класса объекта. Например, есть два класса - кошки и собаки. Мы можем показать огромное количество кошек и собак, и нужно определить, кто где изображен. Это и будет классификацией.
==Задача классификации== - формализованная задача, в которой имеется множество объектов, разделенных некоторым образом на классы. Задано конечное множество объектов, для которых известно, к каким классам они относятся. Классовая принадлежность других объектов неизвестна. Требуется построить алгоритм, способный классифицировать неизвестные объекты.
##### Ключевые характеристики задачи классификации
- Как и в задаче регрессии, у нас есть признаки. Это могут быть площадь квартиры, рост человека, наличие загранпаспорта и т. д.  
- У нас есть ==конечное== количество классов. Например:
	- Тип жилья: эконом-класс, средний класс, бизнес-класс, люкс
	- Уровень образования: нет образования, среднее, средне-специальное, высшее, ученая степень
	- Вернет ли человек кредит: да или нет (бинарная классификация)

#### Дерево решений

==Пример==:
Дерево решений - является ли задача задачей классификации?
  ![[Drawing 2025-04-25 09.20.50.excalidraw]]

==Пример==: Титаник. 

| Класс каюты                             | 1, 2, 3 |
| --------------------------------------- | ------- |
| Пол                                     | м/ж     |
| Возраст                                 | число   |
| Кол-во братьев, сестёр, супруг на борту | число   |
| Кол-во детей/родителей                  | число   |
| Билет №                                 | ###     |

Дерево решений - выжил ли пассажир при кораблекрушении:  
![](Excalidraw/08_02.%20Дерево%20решений.%20Кораблекрушение.png)  
##### Итог
- Классификация - задача на определение класса объекта
- Классов конечное количество
- Ответ да/нет - тоже классификация (бинарная)

#### Кластеризация

Необходимо взять набор объектов и выявить его структуру. Найти конкретные группы - кластеры, которые наиболее похожи внутри группы, но сильно различаются по группа. Полезно, когда у нас огромное количество данных, мы о них ничего не знаем и нам нужно понять, из чего эти данные состоят. Например, потребители, посетители больницы и т. д.  
==Кластеризация (кластерный анализ)== - задача обучения без учителя по разбиению некоторого количества объектов на такие группы, что объекты внутри группы были максимально схожи, а объекты из разных групп максимально отличались. Это задача о том, чтобы взять набор данных, о котором нет информации, и выявить его структуру, выделить группы, которые есть в этом наборе.  
Выделение структуры данных в любом наборе - шаг, предшествующий классификации.  
Зачем это может быть нужно:  
- Сегментация покупателей
- Анализ социальных сетей
- Разбор фотографий на темы
- + выделение структуры данных в любом новом наборе (шаг предшествующий классификации)

Пример:
==Алгоритм k means==
Данные размещаются на диаграмму рассеивания, затем визуально можно предположить количество групп, где точки будут более плотными, ///
Выделяются 3 точки на плоскости - инициализации, размещаемые случайно. Затем разбиваем облако так, чтобы были максимально близко к облакам точек /// Затем точки снова пересчитываются так, чтобы они оказались в центрах групп точек.
%%Как же быстро слайды переключают кошмар%%

#### Ансамбли и бэггинг
Техники, используемые дли повышения точности прогнозирования алгоритмов.

==Ансамбли== иллюстрирует теорема Кондросе о жюри присяжных: если множество присяжных с вероятностью выше 0,5 даст положительный ответ, то при увеличении числа присяжных можно с точностью 100% сказать какой ответ будет в итоге. Так же и наоборот: если шанс ответа ниже 0,5 и количество присяжных повышается, то вероятность 0%. Ещё одним примером станет концепция мудрости толпы - для истинного результата учитывается большое количество мнений людей. Также этот подход тесно связан с теорией больших чисел. Используется это если известно что один алгоритм ошибается на одном отрезке, другой на другом. Данные полученные от алгоритмов смешиваются.

==Бэггинг== - технология классификации, при которой данные из датасета случайно делятся на более мелкие датасеты, на которых отдельно независимо обучается модель. Результаты обучения для каждого мелкого датасета усредняются. Это позволяет снизить количество ошибок при высокой дисперсии на большом датасете.

#### Случайный лес

==Случайный лес== - набор деревьев, полученный по алгоритму беггинга, при этом выбирается некоторое лимитированное количество признаков, затем результаты деревьев усредняются.