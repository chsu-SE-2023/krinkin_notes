Задача сортировки представляет собой перестановку элементов последовательности в порядке возрастания или убывания некоторого признака. Задача интересна сама по себе, но чаще всего сортировка производится в помощь решения других задач (прим.: группировка элементов последовательности по значению некоторого признака, поиск элементов последовательности).

Постановка задачи: пусть необходимо упорядочить $n$ элементов (объектов) $R1, R2, …, Rn$ каждый из которых имеет ключ $ki (k1, k2, …, kn)$ введём на множестве ключей отношение порядка "$<$" (меньше) такое что для любых трёх ключей $a, b, c$ выполняются два свойства:
1. Справедливо одно и только одно утверждение ($a < b$, $a = b$, $b < a$) (закон трихотомии)
2. Из того что $a < b$ и $b < c$ следует что $a < c$ (закон транзитивности)
Любое множество с данным отношением подлежит сортировке в выбранном нами смысле. Причём задача сводится к следующему - найти такую перестановку объектов $Ri1, Ri2, …, Rin$, что $ki1 <= ki2 <= … <= kin$. Для простоты в дальнейшем будем сортировать только одни ключи.

Существует два подхода к сортировке: сортировка внутри последовательности, сортировка с использованием дополнительных последовательностей.
Начнём с первого подхода.
##### Метод прямого выбора

В массиве находится минимальный элемент и меняется местами с первым, среди оставшихся вновь ищется минимальный и меняется со вторым и т.д.

```
#include <iostream>
void vivod(int *a, int n) {
	for (int I = 0; i < n; i++)
		std::cout << a[i] << " ";
	std::cout << std::endl;
}

void selection(int *a, int n) {
	for (int i = 0; i < n-1; i++) {
		int k = i, min = a[i];
		for (int j = i+1; j < n; j++)
			if (a[j]<min) { k = j; min = a[j]; }
		a[k] = a[i];
		a[i] = min;
	}
}

int main() {
	const int n = 10;
	int a[n] = { 2, 6, 3, 9, 1, 5, 2, 8, 9, 10 };
	selection(a, n);
	vivod(a, n);
	return 0;
}
```

Алгоритм сортировки состоит из двух вложенных циклов for, каждый из которых идёт до $n$, поэтому на любом массиве, даже уже отсортированном сложность метода $O(f(n^2))$.
##### Метод прямого включения/вставки

Массив начинает рассматриваться со второго элемента. Этот второй элемент либо остаётся на месте, либо меняется местами с первым. Далее третий элемент включается между первыми двумя уже отсортированными на подходящее для него место. Затем четвёртый между тремя и т.д. Вставка $k$-ого элемента между $k-1$ предыдущими производится сдвигом предыдущих элементов на один вправо, пока не освободится место для $k$-ого элемента.

Пример работы:
2, 6, 3, 9, 1
- 6 > 2 - 6 2 3 9 1
- 3 < 6 - 2 6 6 9 1
- 3 > 2 - 2 3 6 9 1
- 9 > 3 - 2 3 6 9 1
- 1 < 9 - 2 3 6 9 9
- 1 < 6 - 2 3 6 6 9
- 1 < 3 - 2 3 3 6 9
- 1 < 2 - 2 2 3 6 9
- 1 < ? - 1 2 3 6 9

```
#include <iostream>

void vivod(int *a, int n) {
    for (int i = 0; i < n; i++)
        std::cout << a[i] << " ";
    std::cout << std::endl;
}

void insertion(int *a, int n) {
    for (int i = 1; i < n; i++) { // i = 2 для границы
        int j = i, k = a[i]; // a[0] = k; для границы
        while (k > 0 && k < a[j - 1]) { // k > 0 & если нет границы
            a[j] = a[j-1];
            j--;
        }
        a[j] = k;
    }
}

int main() {
    const int n = 10;
    int a[n] = { 2, 6, 3, 9, 1, 5, 2, 8, 9, 10 };
    insertion(a, n);
    vivod(a, n);
    return 0;
}
```

В худшем случае и в среднем двойной вложенный цикл даст сложность $O(f(n^2))$, однако в лучшем (массив уже отсортирован) сложность будет $O(f(n))$, т.к. внутренний цикл while не будет выполняться ни разу.
##### Метод прямого обмена (метод пузырька)

Начиная с конца массива сравниваются два соседних $j$ и $j-1$ элементы и если $j$-ый меньше $j-1$ - они меняются местами и так далее двигаясь к началу массива. В результате на первое место передвинется минимальный элемент. Затем процедура повторяется снова с конца массива до второго элемента и так далее. Метод получил название "пузырьковой сортировки", т.к. если представить массив стоящим вертикально вверх, то на каждом шаге меньшие по значению элементы как пузырьки воздуха в воде всплывают вверх.

```
#include <iostream>

void vivod(int *a, int n) {
    for (int i = 0; i < n; i++)
        std::cout << a[i] << " ";
    std::cout << std::endl;
}

void bubble(int *a, int n) {
    for (int i = 0; i < n - 1; i++)
        for (int j = n-1; j > i; j--)
            if (a[j] < a[j-1])
                std::swap(a[j], a[j-1]);
}

int main() {
    const int n = 10;
    int a[n] = { 2, 6, 3, 9, 1, 5, 2, 8, 9, 10 };
    bubble(a, n);
    vivod(a, n);
    return 0;
}
```
>(Не смотреть код на вики)

Из трёх базовых методов этот самый медленный - двойной цикл for во всех случаях даст сложность $O(f(n^2))$, однако внутри этих циклов гораздо больше перестановок.
##### Шейкерная сортировка

Получена улучшением пузырьковой сортировки:
1. Запоминать были или не были перестановки в процессе некоторого прохода, если не были - сортировку можно завершать.
2. Запоминать не только тот факт что обмен имел место, но и индекс последнего обмена. Очевидно что все элементы до этого индекса уже отсортированы.
3. Проводить сортировку последовательно в двух направлениях по массиву - от конца к началу и от начала к концу.

>"Душная скобочка - это скобочка после do." - Пышницкий К.М.

```
#include <iostream>

void vivod(int *a, int n) {
    for (int i = 0; i < n; i++)
        std::cout << a[i] << " ";
    std::cout << std::endl;
}

void shaker(int *a, int n) {
    int left = 1, right = n-1, k = right;
    do { // Душная скобочка
        for (int j = right; j >= left; j--)
            if (a[j] < a[j - 1]) {
                std::swap(a[j], a[j - 1]);
                k = j;
            }
        left = k + 1;
        for (int j = left; j <= right; j++)
            if (a[j] < a[j - 1]) {
                std::swap(a[j], a[j - 1]);
                k = j;
            }
        right = k - 1;
    } while (left <= right);
}

int main() {
    const int n = 10;
    int a[n] = { 2, 6, 3, 9, 1, 5, 2, 8, 9, 10 };
    shaker(a, n);
    vivod(a, n);
    return 0;
}
```

(Ни в коем случае не сдвигать границу через ++ и --)

Сложность: в лучшем случае на уже отсортированном массиве однократно отработает только первый цикл for, после чего левая граница `left` станет `right+1` и сортировка закончится - $O(f(n))$, в худшем случае (массив отсортирован в обратном порядке) за каждый проход лишь один элемент будем перемещать на своё место - $O(f(n))$
##### Сортировка Шелла

Сначала отдельно группируются и сортируются элементы отстоящие на расстоянии $n/2$ друг от друга, затем на расстоянии $n/4$, $n/8$ и так далее пока на последнем проходе не произойдёт окончательная сортировка всех элементов. Сортировка на каждом проходе программируется как сортировка включением. Выигрыш производится за счёт того, что либо в начале сортируется немного элементов, либо когда их становится много они уже достаточно хорошо отсортированы на предыдущих шагах и сортировка проходит быстро.

- `2` 6 3 9 1 `5` 2 8 9 10
- `2` 2 3 9 1 `5` 6 8 9 10
- `2` 2 `3` 9 `1` 5 `6` 8 `9` 10
- `1` 2 `2` 9 `3` 5 `6` 8 `9` 10
- 1 2 2 `5 3 8 6` 9 9 10
- 1 2 2 3 5 6 8 9 9 10

```
#include <iostream>

void vivod(int *a, int n) {
    for (int i = 0; i < n; i++)
        std::cout << a[i] << " ";
    std::cout << std::endl;
}

void shell(int *a, int n) {
    int step = n/2;
    while (step > 0) {
        for (int i = 0; i < n - step; i++) {
            int j = i;
            while (j >= 0 && a[j] > a[j + step]) {
                std::swap(a[j], a[j+step]);
                j -= step;
            }
        }
        step /= 2;
    }
}

int main() {
    const int n = 10;
    int a[n] = { 2, 6, 3, 9, 1, 5, 2, 8, 9, 10 };
    shell(a, n);
    vivod(a, n);
    return 0;
}
```

Сложность метода: расстояние в группах совсем не обязательно (и даже вредно) менять кратно степени двойки, окончательно неизвестно как именно лучше всего менять расстояние, например хороший результат дают числа $1, 4, 13, 40, 121$ и другие ($lk = 3*lk+1$). Известно что в лучшем случае сложность метода $O(n^{1,2})$.
##### Пирамидальная сортировка

Как было сказано, при изучении бинарных деревьев (каждый узел имеет <= 2 потомков), их можно представить, не только динамической структурой, а ещё и одномерным массивом:
- Корень - нулевой элемент массива
- $Y$ $i$ элемент - потомки располагаются под индексами $2i+1$ (левый), $2i+2$ (правый)

Верно и обратное - любой одномерный массив можно представить в виде сбалансированного бинарного дерева (пирамиды). Пирамидальная сортировка основана именно на этом факте.

Сортировка происходит в этапа:
1. Дерево просеивается, таким образом что у любого узла потомки становятся не больше значения того узла. Половину отсортировали (рассматриваем родителя с потомком).
2. В результате такой перестановки 0-ой элемент станет наибольшим. Поменяем его местами с последним. В полученном массиве на месте стоит только нулевой элемент. Протолкнём по дереву его на нужно место. На нулевом месте оказывается наибольший из оставшихся. Поменяем его местами с предпоследним и т.д.	 Проталкивание одного элемента от корня до нудного поколения в бинарном дереве требует не более $O(log2n)$. Весь алгоритм - $O(n*log2n)$, лучше чем $n^2$

![[Drawing 2025-04-08 10.20.52.excalidraw]]

Некотором минусом является то, что такая сложность абсолютно на любом массиве (случайный, сортированный, обратно сортированный)

Реализация

```
void pushDown(int* a, int root, int bottom) {
    int done = 0; // сделано
    int max_child = 0; // максимальный потомок

    while (root * 2+1 <= bottom && !done) {
        if (root * 2+1 == bottom)
            max_child = root * 2+1;
        else if (a[root * 2+1] > a[root * 2+2])
            max_child = root * 2+1;
        else
            max_child = root * 2+2;
        if (a[root] < a[max_child]) {
            swap(a[root], a[max_child]);
        } else done = 1;
    }
}

void heapSort(int* a, int n) {
    for (int i = n/2-1; i >= 0; i--)
        pushDown(a, i, n - 1);
    for (int i = n-1; i > 0; i--) {
        swap(a[0], a[i]);
        pushDown(a, 0, i - 1);
    }
}
```
##### Быстрая, quick, Хуара сортировка

Самая быстрая + если используется слияние (на файлах), то вообще круто

В массиве выбирается средний элемент $(n/2)$. Объявляется ключевым и все остальные элементы переставляются относительно ключа, таким образом, что слева оказываются меньше ключа, а справа больше. После этого - рекурсивный повтор с левой и правой сторонами массива, пока массив не будет отсортирован.

Если ключ каждый раз будет выбираться, таким образом, что справа и слева от него каждый раз %%одинаковым элементом с меньшим больших%% - $O(log2n)$, на каждом проходе рассматриваем все n элементов $O(n*log2n)$.

В худшем - когда опорный элемент на каждом шаге - минимальный или максимальный, тогда за один проход мы лишь один элемент поставим на место, а остальные справа от него - сложность $O(n^2)$.

##### Карманная сортировка

Данная сортировка возможна в случае когда ключ принимает значения из некоторого дискретного ограниченного множества и границы изменения ключа заранее известны.

В Python - невозможна

Перед началом сортировки заведём массив указателей размером равным мощности множества возможных значений ключей.

Например: если знаем что ключ может принимать значения от 0 до 1000, то объявим массив из 1001 элемента.
Каждый элемент массива - это карман, что будет хранить адрес списка элементов с одним и тем же ключом.

![[Drawing 2025-04-08 10.23.34.excalidraw]]
Для отстутствия пустых карманов, нужен ещё проход и %%запоминать короче вот эти вот адреса%%
Если ключи уникальные, то каждый объект с соответствующим ключом можно хранить внутри элемента массива
Сложность - $O(n)$
##### Внешняя сортировка

Все рассмотренные ранее методы использовали для сортировки лишь ОЗУ, т.к. работа с ней в разы быстрее чем с ПЗУ.

Однако - не всегда данные могут вмещаться в ОЗУ, в этом случае их нужно сортировать в ПЗУ, при этом можно использовать не один, а несколко файлов, так как будем считать, что внешняя память в размерах не ограничена. Сегодня когда размеры ОЗУ также растут - методы внешней сортировки используются и во внутренней памяти.

Прямое слияние
1. Последний файл `a` разбивается на `b` и `с` (1 элемент - `b`, 2-ой - `c`);
2. Части `b` и `с` сливаются в одну последовательность так, что одиночные элементы из b и c становятся упорядоченными парами;
3. Над вновь получившейся последовательностью a проводятся пункты 1 и 2, но файл делится парами, что потом сливается в упорядоченные "четвёрки";
4. Прошлые шаги повторяются, сливая четвёрки в восьмёрки, восьмёрки в 16 и т.д., пока не будет упорядочена вся последовательность

Пример:
1. 
	a: 2 6 9 3 1 5 2 8
	b: 2 9 1 2
	c: 6 3 5 8
2.   
    a: 2 6 3 9 1 5 2 8
	b: 2 6 1 2  
	c: 3 9 2 8
3.   
    a: 2 3 6 9 1 2 5 8
	b: 2 6 1 5
	c: 3 9 1 5
4.   
    a: 1 2 2 3 5 6 8 9

%%Зк%% на начало группы

Действия неоднократной обработки всей последовательности называются проходом, каждый проход включает себя 2 фазы:
1. Разделения
2. Слияния на последовательность из символов

Количество проходов - $O(n*log2n)$, на каждом проходе все элементы просматриваются дважды - $O(n*log2n)$

Легко заметить что непосредственно на сортировку имеет влияние слияние. Можно избавиться от разделения, если пользоваться не тремя, а n последовательностями, разделить начальную последовательность на две `b` и `c`, после чего будем сливать одну пару в файл `b1`, следующую в `c1`, после этого получится 2 файла `b1` -> `b`, `c1` -> `c`.
##### Естественное слияние

На самом деле необязательно сливать последовательности по группам $n^2$, может оказаться что в реальной последовательности некоторые из них уже упорядочены или что не мешает сразу сливать такие части как в примере:

Уже упорядочены: 2, 6, 9 - сольём её с тройкой (3)
2 6 9 3 – 1 5 2 8
И сортировка пройдёт за 2 прохода
Сложность не хуже $O(n*log2n)$
##### Многопутевое слияние

Очевидный выйгрыш в скорости может дать деление исходной последовательности не на два файла, а на %%2k%% – в этом случае число проходов $O(log2n)$. Однако при большом k нужно очень часто переключться между файлами.
##### Многофазное включение

В основе лежит отказ от понятия "проход". Будем сортировать последовательность с использоанием трёх файлов, %%разделённых изначально на два - естественным образом примем количество серий - различно, пусто в одном из зелий, в другом 8%%. Как только сольём 8 серий в третий файл, то второй окажется пустым, после этого будем сливать %%1аз%% в 2 и т.д